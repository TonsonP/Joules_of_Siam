{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to use PyTorch LSTMs for time series regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Residental &lt;150</th>\n",
       "      <th>Residental &gt; 150</th>\n",
       "      <th>Residental Total</th>\n",
       "      <th>Small General</th>\n",
       "      <th>Medium General</th>\n",
       "      <th>Large General</th>\n",
       "      <th>Specific Business</th>\n",
       "      <th>Gov &amp; Nonprofit</th>\n",
       "      <th>Agriculture Pumping</th>\n",
       "      <th>Temporary</th>\n",
       "      <th>Stand By Rate</th>\n",
       "      <th>Interruptible Rate</th>\n",
       "      <th>Free of Charge</th>\n",
       "      <th>Total</th>\n",
       "      <th>Direct Customer</th>\n",
       "      <th>Grand total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-1</th>\n",
       "      <td>488</td>\n",
       "      <td>1036</td>\n",
       "      <td>1524</td>\n",
       "      <td>693</td>\n",
       "      <td>1415</td>\n",
       "      <td>2958</td>\n",
       "      <td>236</td>\n",
       "      <td>246</td>\n",
       "      <td>19</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>7199</td>\n",
       "      <td>128</td>\n",
       "      <td>7327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-2</th>\n",
       "      <td>510</td>\n",
       "      <td>1088</td>\n",
       "      <td>1597</td>\n",
       "      <td>719</td>\n",
       "      <td>1406</td>\n",
       "      <td>2797</td>\n",
       "      <td>238</td>\n",
       "      <td>260</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>76.0</td>\n",
       "      <td>74</td>\n",
       "      <td>7224</td>\n",
       "      <td>135</td>\n",
       "      <td>7359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-3</th>\n",
       "      <td>597</td>\n",
       "      <td>1246</td>\n",
       "      <td>1842</td>\n",
       "      <td>816</td>\n",
       "      <td>1664</td>\n",
       "      <td>3199</td>\n",
       "      <td>277</td>\n",
       "      <td>301</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>76</td>\n",
       "      <td>8316</td>\n",
       "      <td>155</td>\n",
       "      <td>8471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-4</th>\n",
       "      <td>662</td>\n",
       "      <td>1387</td>\n",
       "      <td>2049</td>\n",
       "      <td>863</td>\n",
       "      <td>1574</td>\n",
       "      <td>3014</td>\n",
       "      <td>290</td>\n",
       "      <td>287</td>\n",
       "      <td>23</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>86</td>\n",
       "      <td>8307</td>\n",
       "      <td>154</td>\n",
       "      <td>8461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-5</th>\n",
       "      <td>652</td>\n",
       "      <td>1338</td>\n",
       "      <td>1990</td>\n",
       "      <td>884</td>\n",
       "      <td>1670</td>\n",
       "      <td>3230</td>\n",
       "      <td>278</td>\n",
       "      <td>306</td>\n",
       "      <td>15</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>98.0</td>\n",
       "      <td>77</td>\n",
       "      <td>8582</td>\n",
       "      <td>149</td>\n",
       "      <td>8730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Residental <150  Residental > 150  Residental Total  Small General  \\\n",
       "Date                                                                         \n",
       "2002-1              488              1036              1524            693   \n",
       "2002-2              510              1088              1597            719   \n",
       "2002-3              597              1246              1842            816   \n",
       "2002-4              662              1387              2049            863   \n",
       "2002-5              652              1338              1990            884   \n",
       "\n",
       "        Medium General  Large General  Specific Business  Gov & Nonprofit  \\\n",
       "Date                                                                        \n",
       "2002-1            1415           2958                236              246   \n",
       "2002-2            1406           2797                238              260   \n",
       "2002-3            1664           3199                277              301   \n",
       "2002-4            1574           3014                290              287   \n",
       "2002-5            1670           3230                278              306   \n",
       "\n",
       "        Agriculture Pumping  Temporary  Stand By Rate  Interruptible Rate  \\\n",
       "Date                                                                        \n",
       "2002-1                   19         29              1                 NaN   \n",
       "2002-2                   26         31              1                76.0   \n",
       "2002-3                   24         31              0                85.0   \n",
       "2002-4                   23         34              0                86.0   \n",
       "2002-5                   15         34              1                98.0   \n",
       "\n",
       "        Free of Charge  Total  Direct Customer  Grand total  \n",
       "Date                                                         \n",
       "2002-1              78   7199              128         7327  \n",
       "2002-2              74   7224              135         7359  \n",
       "2002-3              76   8316              155         8471  \n",
       "2002-4              86   8307              154         8461  \n",
       "2002-5              77   8582              149         8730  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/Users/atichetsurakul/Desktop/JAN23/BiA/Joules_of_Siam_Data - Electricity_Consumption_Monthly.csv\", index_col=\"Date\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "pio.templates.default = \"plotly_white\"\n",
    "\n",
    "plot_template = dict(\n",
    "    layout=go.Layout({\n",
    "        \"font_size\": 18,\n",
    "        \"xaxis_title_font_size\": 24,\n",
    "        \"yaxis_title_font_size\": 24})\n",
    ")\n",
    "\n",
    "# fig = px.line(df, labels=dict(\n",
    "#     created_at=\"Date\", value=\"PM2.5 (ug/m3)\", variable=\"Sensor\"\n",
    "# ))\n",
    "# fig.update_layout(\n",
    "#   template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    "# )\n",
    "# fig.show()\n",
    "# fig.write_image(\"pm25_data.png\", width=1200, height=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig.update_yaxes(range = [0, 60])\n",
    "# fig.show()\n",
    "# fig.write_image(\"pm25_data_zoomed.png\", width=1200, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sensor = \"Grand total\" # Comsumption and FT\n",
    "features = list(df.columns.difference([target_sensor]))\n",
    "\n",
    "forecast_lead = 15\n",
    "target = f\"{target_sensor}_lead{forecast_lead}\"\n",
    "\n",
    "df[target] = df[target_sensor].shift(-forecast_lead)\n",
    "df = df.iloc[:-forecast_lead]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a hold-out test set and preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set fraction: 0.08860759493670886\n"
     ]
    }
   ],
   "source": [
    "test_start = '2020-1'   #Date\n",
    "\n",
    "df_train = df.loc[:test_start].copy()\n",
    "df_test = df.loc[test_start:].copy()\n",
    "\n",
    "print(\"Test set fraction:\", len(df_test) / len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the features and target, based on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = df_train[target].mean()\n",
    "target_stdev = df_train[target].std()\n",
    "\n",
    "for c in df_train.columns:\n",
    "    mean = df_train[c].mean()\n",
    "    stdev = df_train[c].std()\n",
    "\n",
    "    df_train[c] = (df_train[c] - mean) / stdev\n",
    "    df_test[c] = (df_test[c] - mean) / stdev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create datasets that PyTorch `DataLoader` can work with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, dataframe, target, features, sequence_length=5):\n",
    "        self.features = features\n",
    "        self.target = target\n",
    "        self.sequence_length = sequence_length\n",
    "        self.y = torch.tensor(dataframe[self.target].values).float()\n",
    "        self.X = torch.tensor(dataframe[self.features].values).float()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        if i >= self.sequence_length - 1:\n",
    "            i_start = i - self.sequence_length + 1\n",
    "            x = self.X[i_start:(i + 1), :]\n",
    "        else:\n",
    "            padding = self.X[0].repeat(self.sequence_length - i - 1, 1)\n",
    "            x = self.X[0:(i + 1), :]\n",
    "            x = torch.cat((padding, x), 0)\n",
    "\n",
    "        return x, self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1598, -0.2793, -1.2205,  0.3228,  0.4190, -1.5506, -1.4474, -1.5106,\n",
      "         -1.3918, -1.4566, -1.5513, -1.3258, -0.5652, -1.3331, -1.5636],\n",
      "        [-0.0750,  0.2994, -1.2361,  0.3574, -0.2719, -1.3660, -1.5184, -1.7798,\n",
      "         -1.4166, -1.5104, -1.5629, -1.4718, -0.8122, -1.2417, -1.5263],\n",
      "        [ 0.5512,  0.5099, -1.2049,  0.5595,  0.0505, -1.0393, -0.9277, -0.4103,\n",
      "         -1.0347, -1.0010, -1.1581, -1.0726, -0.7298, -1.1504, -1.0637],\n",
      "        [ 0.2381, -0.5950, -1.2205,  0.5884, -0.3640, -1.3403, -1.2259,  0.4559,\n",
      "         -0.7621, -0.6502, -1.0049, -0.8778, -0.2359, -1.1504, -1.0961]])\n"
     ]
    }
   ],
   "source": [
    "i = 27\n",
    "sequence_length = 4\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "X, y = train_dataset[i]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0750,  0.2994, -1.2361,  0.3574, -0.2719, -1.3660, -1.5184, -1.7798,\n",
      "         -1.4166, -1.5104, -1.5629, -1.4718, -0.8122, -1.2417, -1.5263],\n",
      "        [ 0.5512,  0.5099, -1.2049,  0.5595,  0.0505, -1.0393, -0.9277, -0.4103,\n",
      "         -1.0347, -1.0010, -1.1581, -1.0726, -0.7298, -1.1504, -1.0637],\n",
      "        [ 0.2381, -0.5950, -1.2205,  0.5884, -0.3640, -1.3403, -1.2259,  0.4559,\n",
      "         -0.7621, -0.6502, -1.0049, -0.8778, -0.2359, -1.1504, -1.0961],\n",
      "        [-0.7795,  0.2994, -1.2205,  0.6230, -0.3640, -1.0284, -0.7176,  0.3154,\n",
      "         -0.8277, -0.7268, -0.9875, -0.9947, -0.6475, -1.0895, -0.9262]])\n"
     ]
    }
   ],
   "source": [
    "X, y = train_dataset[i + 1]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Agriculture Pumping  Direct Customer  Free of Charge  Gov & Nonprofit  \\\n",
      "Date                                                                            \n",
      "2004-1             0.159799        -0.279315       -1.220532         0.322803   \n",
      "2004-2            -0.075030         0.299439       -1.236125         0.357443   \n",
      "2004-3             0.551182         0.509894       -1.204940         0.559510   \n",
      "2004-4             0.238076        -0.594998       -1.220532         0.588377   \n",
      "\n",
      "        Interruptible Rate  Large General  Medium General  Residental <150  \\\n",
      "Date                                                                         \n",
      "2004-1            0.418979      -1.550586       -1.447393        -1.510605   \n",
      "2004-2           -0.271857      -1.365996       -1.518386        -1.779822   \n",
      "2004-3            0.050533      -1.039262       -0.927729        -0.410326   \n",
      "2004-4           -0.363968      -1.340331       -1.225897         0.455852   \n",
      "\n",
      "        Residental > 150  Residental Total  Small General  Specific Business  \\\n",
      "Date                                                                           \n",
      "2004-1         -1.391841         -1.456601      -1.551347          -1.325767   \n",
      "2004-2         -1.416623         -1.510364      -1.562912          -1.471843   \n",
      "2004-3         -1.034695         -1.000961      -1.158127          -1.072569   \n",
      "2004-4         -0.762097         -0.650158      -1.004887          -0.877801   \n",
      "\n",
      "        Stand By Rate  Temporary     Total  \n",
      "Date                                        \n",
      "2004-1      -0.565215  -1.333066 -1.563602  \n",
      "2004-2      -0.812165  -1.241736 -1.526318  \n",
      "2004-3      -0.729848  -1.150405 -1.063668  \n",
      "2004-4      -0.235949  -1.150405 -1.096141  \n"
     ]
    }
   ],
   "source": [
    "print(df_train[features].iloc[(i - sequence_length + 1): (i + 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 15])\n",
      "tensor([[[ 3.1635e-01,  2.1935e+00, -3.5496e-02,  1.4659e+00, -8.7634e-02,\n",
      "           2.2227e-01,  8.5060e-04,  4.2074e-01,  4.5492e-02,  9.1768e-02,\n",
      "           5.0445e-02, -1.1085e-02,  9.3317e-02, -5.1109e-01,  2.2005e-01],\n",
      "         [-1.0926e+00, -1.7409e-01, -5.1089e-02,  1.2870e+00, -5.4819e-01,\n",
      "           1.6995e-01, -1.4965e-01,  4.6173e-02, -1.1777e-01, -1.0312e-01,\n",
      "          -1.1147e-01, -1.4742e-01, -2.3595e-01, -6.0242e-01,  6.4092e-02],\n",
      "         [-1.3275e+00,  1.4160e-01, -2.3820e-01,  1.4197e+00, -1.2851e+00,\n",
      "           1.1566e-01, -1.3545e-01, -1.4111e-01, -1.8192e-01, -1.8377e-01,\n",
      "          -1.5195e-01, -2.4481e-01, -4.0058e-01, -5.7198e-01,  6.7619e-03],\n",
      "         [-1.3275e+00, -2.7931e-01,  7.3652e-02,  1.1426e+00, -6.8636e-01,\n",
      "           2.6175e-01, -2.9164e-01,  2.1004e-01, -2.1399e-01, -1.7301e-01,\n",
      "          -1.5195e-01, -2.1559e-01, -1.5363e-01, -4.8064e-01,  4.5249e-02]],\n",
      "\n",
      "        [[ 5.5118e-01, -1.3842e+00,  1.7421e+00, -1.1552e+00, -7.3241e-01,\n",
      "           1.3584e+00,  1.8097e+00, -1.5281e-01,  1.9755e+00,  1.8041e+00,\n",
      "           1.6349e+00,  1.6347e+00,  1.9866e+00,  1.3155e+00,  1.6276e+00],\n",
      "         [-2.3158e-01, -1.8051e+00,  1.4926e+00, -1.1610e+00, -7.7847e-01,\n",
      "           1.1235e+00,  1.4548e+00, -5.9761e-01,  1.5790e+00,  1.3875e+00,\n",
      "           1.3805e+00,  1.0699e+00,  2.1512e+00,  1.1633e+00,  1.2869e+00],\n",
      "         [ 1.4122e+00, -1.4368e+00,  1.8200e+00, -1.1552e+00, -1.3311e+00,\n",
      "           1.2992e+00,  1.6621e+00, -1.4111e-01,  1.8750e+00,  1.7127e+00,\n",
      "           1.5424e+00,  1.5763e+00,  2.5795e-01,  1.2851e+00,  1.5334e+00],\n",
      "         [-1.5331e-01, -2.1734e+00,  1.8200e+00, -1.1610e+00, -4.1002e-01,\n",
      "           1.0732e+00,  1.3753e+00, -5.6249e-01,  1.5441e+00,  1.3592e+00,\n",
      "           1.3053e+00,  1.1673e+00,  7.5185e-01,  1.1938e+00,  1.2456e+00]],\n",
      "\n",
      "        [[-1.5623e+00, -2.0156e+00,  1.4614e+00, -1.1725e+00, -5.9425e-01,\n",
      "           1.3229e+00,  1.1367e+00,  1.9834e-01,  1.3239e+00,  1.2436e+00,\n",
      "           1.2619e+00,  1.1283e+00,  9.3317e-02,  1.1024e+00,  1.2480e+00],\n",
      "         [-1.4057e+00, -2.6996e+00,  1.4146e+00, -1.1667e+00, -1.7975e-01,\n",
      "           1.2864e+00,  1.1424e+00, -5.7420e-01,  9.7699e-01,  8.3370e-01,\n",
      "           9.9591e-01,  9.0432e-01, -7.1316e-02,  9.8065e-01,  1.0676e+00],\n",
      "         [-1.5331e-01, -2.2260e+00,  1.5082e+00, -1.1725e+00, -8.7634e-02,\n",
      "           9.1720e-01,  6.2274e-01, -6.2102e-01,  7.8019e-01,  6.4821e-01,\n",
      "           8.7736e-01,  7.8746e-01, -5.6522e-01,  9.5021e-01,  7.7330e-01],\n",
      "         [ 1.1774e+00, -1.2264e+00,  1.6173e+00, -1.1667e+00, -2.7186e-01,\n",
      "           1.0801e+00,  7.3917e-01, -7.9659e-01,  4.8136e-01,  3.5252e-01,\n",
      "           6.5762e-01,  9.9197e-01, -2.3595e-01,  7.0666e-01,  7.5286e-01]]])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "torch.manual_seed(99)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=3, shuffle=True)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the datasets and data loaders for real"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using just 4 time periods to forecast 15 time periods ahead seems challenging, so let's\n",
    "use sequences of length 30 (60 minutes) instead.\n",
    "\n",
    "The PyTorch `DataLoader` is a very convenient way to iterate through these datasets. For\n",
    "the training set we'll shuffle (the rows *within* each training sequence are not\n",
    "shuffled, only the order in which we draw those blocks). For the test set, shuffling\n",
    "isn't necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: torch.Size([4, 30, 15])\n",
      "Target shape: torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(101)\n",
    "\n",
    "batch_size = 4\n",
    "sequence_length = 30\n",
    "\n",
    "train_dataset = SequenceDataset(\n",
    "    df_train,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "test_dataset = SequenceDataset(\n",
    "    df_test,\n",
    "    target=target,\n",
    "    features=features,\n",
    "    sequence_length=sequence_length\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "X, y = next(iter(train_loader))\n",
    "\n",
    "print(\"Features shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The model and learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class ShallowRegressionLSTM(nn.Module):\n",
    "    def __init__(self, num_sensors, hidden_units):\n",
    "        super().__init__()\n",
    "        self.num_sensors = num_sensors  # this is the number of features\n",
    "        self.hidden_units = hidden_units\n",
    "        self.num_layers = 1\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=num_sensors,\n",
    "            hidden_size=hidden_units,\n",
    "            batch_first=True,\n",
    "            num_layers=self.num_layers\n",
    "        )\n",
    "\n",
    "        self.linear = nn.Linear(in_features=self.hidden_units, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_units).requires_grad_()\n",
    "        \n",
    "        _, (hn, _) = self.lstm(x, (h0, c0))\n",
    "        out = self.linear(hn[0]).flatten()  # First dim of Hn is num_layers, which is set to 1 above.\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 5e-5\n",
    "num_hidden_units = 3\n",
    "\n",
    "model = ShallowRegressionLSTM(num_sensors=len(features), hidden_units=num_hidden_units)\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    \n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = loss_function(output, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Train loss: {avg_loss}\")\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "    \n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += loss_function(output, y).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    print(f\"Test loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "--------\n",
      "Test loss: 3.985864202181498\n",
      "\n",
      "Epoch 0\n",
      "---------\n",
      "Train loss: nan\n",
      "Test loss: nan\n",
      "\n",
      "Epoch 1\n",
      "---------\n",
      "Train loss: nan\n",
      "Test loss: nan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Untrained test\\n--------\")\n",
    "test_model(test_loader, model, loss_function)\n",
    "print()\n",
    "\n",
    "for ix_epoch in range(2):\n",
    "    print(f\"Epoch {ix_epoch}\\n---------\")\n",
    "    train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_model(test_loader, model, loss_function)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(data_loader, model):\n",
    "    \"\"\"Just like `test_loop` function but keep track of the outputs instead of the loss\n",
    "    function.\n",
    "    \"\"\"\n",
    "    output = torch.tensor([])\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, _ in data_loader:\n",
    "            y_star = model(X)\n",
    "            output = torch.cat((output, y_star), 0)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Grand total_lead15  Model forecast\n",
      "Date                                      \n",
      "2002-1              8860.0             NaN\n",
      "2002-2              9437.0             NaN\n",
      "2002-3              9146.0             NaN\n",
      "2002-4              9089.0             NaN\n",
      "2002-5              9344.0             NaN\n",
      "...                    ...             ...\n",
      "2021-5             17276.0             NaN\n",
      "2021-6             16508.0             NaN\n",
      "2021-7             16032.0             NaN\n",
      "2021-8             16061.0             NaN\n",
      "2021-9             15191.0             NaN\n",
      "\n",
      "[238 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_eval_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "ystar_col = \"Model forecast\"\n",
    "df_train[ystar_col] = predict(train_eval_loader, model).numpy()\n",
    "df_test[ystar_col] = predict(test_loader, model).numpy()\n",
    "\n",
    "df_out = pd.concat((df_train, df_test))[[target, ystar_col]]\n",
    "\n",
    "for c in df_out.columns:\n",
    "    df_out[c] = df_out[c] * target_stdev + target_mean\n",
    "\n",
    "print(df_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = px.line(df_out, labels={'value': \"PM2.5 (ug/m3)\", 'created_at': 'Date'})\n",
    "# fig.add_vline(x=test_start, line_width=4, line_dash=\"dash\")\n",
    "# fig.add_annotation(xref=\"paper\", x=0.75, yref=\"paper\", y=0.8, text=\"Test set start\", showarrow=False)\n",
    "# fig.update_layout(\n",
    "#   template=plot_template, legend=dict(orientation='h', y=1.02, title_text=\"\")\n",
    "# )\n",
    "# fig.show()\n",
    "# fig.write_image(\"pm25_forecast.png\", width=1200, height=600)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "afa1953de36fe74bf64e0007a050b01fd0993b8df6207b9778c7f34846b9bbf9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('complete3.8': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
