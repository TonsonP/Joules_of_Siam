{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Date</th>\n",
       "      <th>Population (million)</th>\n",
       "      <th>Temperature (celsius)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP (million bahts)</th>\n",
       "      <th>Peak Load (MW)</th>\n",
       "      <th>Generation (GWh)</th>\n",
       "      <th>Consumption (GWh)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2002-Jan</td>\n",
       "      <td>63.25</td>\n",
       "      <td>26.45</td>\n",
       "      <td>70.23</td>\n",
       "      <td>480343.33</td>\n",
       "      <td>14552.5</td>\n",
       "      <td>8261.93</td>\n",
       "      <td>7326.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2002-Feb</td>\n",
       "      <td>63.21</td>\n",
       "      <td>26.49</td>\n",
       "      <td>70.23</td>\n",
       "      <td>480343.33</td>\n",
       "      <td>15260.8</td>\n",
       "      <td>8187.95</td>\n",
       "      <td>7359.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2002-Mar</td>\n",
       "      <td>63.17</td>\n",
       "      <td>26.52</td>\n",
       "      <td>70.23</td>\n",
       "      <td>480343.33</td>\n",
       "      <td>16485.3</td>\n",
       "      <td>9687.11</td>\n",
       "      <td>8471.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>Apr</td>\n",
       "      <td>2002-Apr</td>\n",
       "      <td>63.13</td>\n",
       "      <td>26.55</td>\n",
       "      <td>70.23</td>\n",
       "      <td>470404.67</td>\n",
       "      <td>16681.1</td>\n",
       "      <td>9378.36</td>\n",
       "      <td>8461.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>May</td>\n",
       "      <td>2002-May</td>\n",
       "      <td>63.09</td>\n",
       "      <td>26.58</td>\n",
       "      <td>70.07</td>\n",
       "      <td>470404.67</td>\n",
       "      <td>16293.1</td>\n",
       "      <td>9654.67</td>\n",
       "      <td>8730.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Month      Date  Population (million)  Temperature (celsius)    CPI   \n",
       "0  2002   Jan  2002-Jan                 63.25                  26.45  70.23  \\\n",
       "1  2002   Feb  2002-Feb                 63.21                  26.49  70.23   \n",
       "2  2002   Mar  2002-Mar                 63.17                  26.52  70.23   \n",
       "3  2002   Apr  2002-Apr                 63.13                  26.55  70.23   \n",
       "4  2002   May  2002-May                 63.09                  26.58  70.07   \n",
       "\n",
       "   GDP (million bahts)  Peak Load (MW)  Generation (GWh)  Consumption (GWh)  \n",
       "0            480343.33         14552.5           8261.93            7326.80  \n",
       "1            480343.33         15260.8           8187.95            7359.06  \n",
       "2            480343.33         16485.3           9687.11            8471.25  \n",
       "3            470404.67         16681.1           9378.36            8461.08  \n",
       "4            470404.67         16293.1           9654.67            8730.29  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('monthly_dataset.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 252 entries, 0 to 251\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Year                   252 non-null    int64  \n",
      " 1   Month                  252 non-null    object \n",
      " 2   Date                   252 non-null    object \n",
      " 3   Population (million)   252 non-null    float64\n",
      " 4   Temperature (celsius)  252 non-null    float64\n",
      " 5   CPI                    252 non-null    float64\n",
      " 6   GDP (million bahts)    252 non-null    float64\n",
      " 7   Peak Load (MW)         252 non-null    float64\n",
      " 8   Generation (GWh)       252 non-null    float64\n",
      " 9   Consumption (GWh)      252 non-null    float64\n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 19.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population (million)</th>\n",
       "      <th>Temperature (celsius)</th>\n",
       "      <th>CPI</th>\n",
       "      <th>GDP (million bahts)</th>\n",
       "      <th>Peak Load (MW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66.52</td>\n",
       "      <td>26.91</td>\n",
       "      <td>99.65</td>\n",
       "      <td>870261.00</td>\n",
       "      <td>26928.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66.07</td>\n",
       "      <td>27.40</td>\n",
       "      <td>98.87</td>\n",
       "      <td>814136.00</td>\n",
       "      <td>27235.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66.11</td>\n",
       "      <td>27.54</td>\n",
       "      <td>97.72</td>\n",
       "      <td>847183.00</td>\n",
       "      <td>25312.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.53</td>\n",
       "      <td>26.69</td>\n",
       "      <td>85.50</td>\n",
       "      <td>679751.00</td>\n",
       "      <td>20885.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.16</td>\n",
       "      <td>26.74</td>\n",
       "      <td>100.78</td>\n",
       "      <td>812200.33</td>\n",
       "      <td>27642.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Population (million)  Temperature (celsius)     CPI  GDP (million bahts)   \n",
       "0                 66.52                  26.91   99.65            870261.00  \\\n",
       "1                 66.07                  27.40   98.87            814136.00   \n",
       "2                 66.11                  27.54   97.72            847183.00   \n",
       "3                 63.53                  26.69   85.50            679751.00   \n",
       "4                 66.16                  26.74  100.78            812200.33   \n",
       "\n",
       "   Peak Load (MW)  \n",
       "0         26928.0  \n",
       "1         27235.0  \n",
       "2         25312.3  \n",
       "3         20885.6  \n",
       "4         27642.1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(['Year', 'Month', 'Date', 'Generation (GWh)', 'Consumption (GWh)'], axis=1)\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((252, 4), (252,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop('Peak Load (MW)', axis=1).values\n",
    "y = df['Peak Load (MW)'].values\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 240\n",
    "\n",
    "X_train = X[:train_len]\n",
    "X_test = X[train_len:]\n",
    "\n",
    "y_train = y[:train_len]\n",
    "y_test = y[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# pickle.dump(scaler, open('monthly_peak_scaler.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "scaler = pickle.load(open('monthly_peak_scaler.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 4), (12, 4), (240,), (12,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neural_network import MLPRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# param_grid = {\n",
    "#     'hidden_layer_sizes': [(16, 8), (32, 16), (64, 32), (16, 16), (32, 32), (64, 64)],\n",
    "#     'activation': ['tanh', 'relu'],\n",
    "#     'alpha': [0.001, 0.01, 0.1]\n",
    "# }\n",
    "\n",
    "# mlp = MLPRegressor(max_iter=1000)\n",
    "# grid_search = GridSearchCV(mlp, param_grid, cv=5)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "# print(\"Validation score: {:.3f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "# from keras.wrappers.scikit_learn import KerasRegressor\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def create_ANN():\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "#     model.add(Dense(64, activation='relu'))\n",
    "#     model.add(Dense(1, activation='linear'))\n",
    "#     model.compile(loss='mse', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# model = KerasRegressor(build_fn=create_ANN, verbose=0)\n",
    "\n",
    "# batch_size = [32, 48, 64]\n",
    "# epochs = [1000, 3000, 5000]\n",
    "\n",
    "# param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "# grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=5)\n",
    "# grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "6/6 [==============================] - 1s 36ms/step - loss: 218867968.0000 - val_loss: 4530505.5000\n",
      "Epoch 2/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 73245976.0000 - val_loss: 4497982.5000\n",
      "Epoch 3/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 41836256.0000 - val_loss: 3423537.0000\n",
      "Epoch 4/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 21558682.0000 - val_loss: 4191224.7500\n",
      "Epoch 5/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 12621648.0000 - val_loss: 3839548.0000\n",
      "Epoch 6/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8705613.0000 - val_loss: 3557732.7500\n",
      "Epoch 7/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6961623.5000 - val_loss: 3569572.2500\n",
      "Epoch 8/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4688912.0000 - val_loss: 3552121.2500\n",
      "Epoch 9/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4507623.5000 - val_loss: 4568343.0000\n",
      "Epoch 10/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4229037.0000 - val_loss: 5276103.0000\n",
      "Epoch 11/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4473150.0000 - val_loss: 5168836.0000\n",
      "Epoch 12/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3459401.7500 - val_loss: 3878373.2500\n",
      "Epoch 13/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2904559.0000 - val_loss: 3844184.7500\n",
      "Epoch 14/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2894400.7500 - val_loss: 3514793.0000\n",
      "Epoch 15/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2813574.0000 - val_loss: 3575222.0000\n",
      "Epoch 16/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3044925.7500 - val_loss: 3422716.0000\n",
      "Epoch 17/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2958495.2500 - val_loss: 3452687.2500\n",
      "Epoch 18/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2927827.7500 - val_loss: 3504931.7500\n",
      "Epoch 19/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2910047.2500 - val_loss: 3450252.2500\n",
      "Epoch 20/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2926694.0000 - val_loss: 3794406.0000\n",
      "Epoch 21/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2975886.2500 - val_loss: 3493276.0000\n",
      "Epoch 22/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3016029.2500 - val_loss: 3432533.2500\n",
      "Epoch 23/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2931117.7500 - val_loss: 3745196.0000\n",
      "Epoch 24/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3396869.0000 - val_loss: 3689204.0000\n",
      "Epoch 25/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3087796.2500 - val_loss: 3998598.2500\n",
      "Epoch 26/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3550224.2500 - val_loss: 3522616.2500\n",
      "Epoch 27/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3159320.0000 - val_loss: 4089950.2500\n",
      "Epoch 28/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3462290.0000 - val_loss: 3431754.0000\n",
      "Epoch 29/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3426915.2500 - val_loss: 5136219.5000\n",
      "Epoch 30/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3844279.2500 - val_loss: 4453762.5000\n",
      "Epoch 31/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4491924.5000 - val_loss: 4063743.0000\n",
      "Epoch 32/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3334198.2500 - val_loss: 3996548.0000\n",
      "Epoch 33/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3266840.2500 - val_loss: 3611222.2500\n",
      "Epoch 34/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2941777.7500 - val_loss: 3660482.0000\n",
      "Epoch 35/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2889037.0000 - val_loss: 3879590.2500\n",
      "Epoch 36/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3006900.2500 - val_loss: 3427230.7500\n",
      "Epoch 37/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3383775.7500 - val_loss: 3456741.7500\n",
      "Epoch 38/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3818654.0000 - val_loss: 5785846.0000\n",
      "Epoch 39/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3399370.0000 - val_loss: 3628536.7500\n",
      "Epoch 40/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3051482.7500 - val_loss: 3463247.7500\n",
      "Epoch 41/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3128470.7500 - val_loss: 3563873.7500\n",
      "Epoch 42/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2909501.2500 - val_loss: 3432766.0000\n",
      "Epoch 43/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3029842.7500 - val_loss: 3501283.7500\n",
      "Epoch 44/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3007393.2500 - val_loss: 3930212.2500\n",
      "Epoch 45/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3239821.7500 - val_loss: 4570643.5000\n",
      "Epoch 46/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3276833.7500 - val_loss: 3949866.2500\n",
      "Epoch 47/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3111597.0000 - val_loss: 3421854.2500\n",
      "Epoch 48/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2964102.7500 - val_loss: 3890222.7500\n",
      "Epoch 49/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3039098.0000 - val_loss: 3432404.7500\n",
      "Epoch 50/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3626712.2500 - val_loss: 3595256.0000\n",
      "Epoch 51/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3027159.2500 - val_loss: 4743732.5000\n",
      "Epoch 52/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3055387.2500 - val_loss: 3464078.0000\n",
      "Epoch 53/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3312944.0000 - val_loss: 3902162.0000\n",
      "Epoch 54/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3489852.2500 - val_loss: 3815084.7500\n",
      "Epoch 55/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3562773.7500 - val_loss: 3677374.2500\n",
      "Epoch 56/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3520648.0000 - val_loss: 3509696.7500\n",
      "Epoch 57/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2924440.7500 - val_loss: 3667951.7500\n",
      "Epoch 58/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2995803.7500 - val_loss: 3439699.0000\n",
      "Epoch 59/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2839000.0000 - val_loss: 3671909.7500\n",
      "Epoch 60/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2941386.7500 - val_loss: 3658167.2500\n",
      "Epoch 61/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3476297.0000 - val_loss: 4488977.5000\n",
      "Epoch 62/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3717266.0000 - val_loss: 7793491.5000\n",
      "Epoch 63/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4843408.5000 - val_loss: 5401204.5000\n",
      "Epoch 64/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3546478.0000 - val_loss: 4007319.2500\n",
      "Epoch 65/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3463879.2500 - val_loss: 5194806.0000\n",
      "Epoch 66/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5522480.0000 - val_loss: 3749880.7500\n",
      "Epoch 67/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7047472.0000 - val_loss: 3525503.7500\n",
      "Epoch 68/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 8203882.0000 - val_loss: 3573549.0000\n",
      "Epoch 69/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5553113.5000 - val_loss: 5341067.5000\n",
      "Epoch 70/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4517664.5000 - val_loss: 5614973.5000\n",
      "Epoch 71/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3836197.2500 - val_loss: 3899714.7500\n",
      "Epoch 72/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3781421.2500 - val_loss: 3606962.7500\n",
      "Epoch 73/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3398304.7500 - val_loss: 3441954.0000\n",
      "Epoch 74/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3232733.0000 - val_loss: 3442314.7500\n",
      "Epoch 75/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4478712.5000 - val_loss: 3567455.7500\n",
      "Epoch 76/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4564971.5000 - val_loss: 3422909.7500\n",
      "Epoch 77/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3862129.7500 - val_loss: 3744962.0000\n",
      "Epoch 78/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3068873.0000 - val_loss: 3533904.0000\n",
      "Epoch 79/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3145660.2500 - val_loss: 4653385.5000\n",
      "Epoch 80/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3322620.0000 - val_loss: 4319167.5000\n",
      "Epoch 81/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3320691.0000 - val_loss: 3495217.2500\n",
      "Epoch 82/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3328024.7500 - val_loss: 3593908.7500\n",
      "Epoch 83/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3702495.0000 - val_loss: 3928944.7500\n",
      "Epoch 84/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3622361.2500 - val_loss: 5774200.0000\n",
      "Epoch 85/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3796491.2500 - val_loss: 4120938.0000\n",
      "Epoch 86/5000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3107935.0000 - val_loss: 3599112.7500\n",
      "Epoch 87/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2843624.7500 - val_loss: 4281050.0000\n",
      "Epoch 88/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3062662.2500 - val_loss: 3632321.2500\n",
      "Epoch 89/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3395882.2500 - val_loss: 4299892.0000\n",
      "Epoch 90/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3235702.7500 - val_loss: 3832086.0000\n",
      "Epoch 91/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3432133.0000 - val_loss: 3454728.7500\n",
      "Epoch 92/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3856956.0000 - val_loss: 3793932.7500\n",
      "Epoch 93/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3761866.7500 - val_loss: 3555746.2500\n",
      "Epoch 94/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2922132.0000 - val_loss: 3602602.0000\n",
      "Epoch 95/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3010541.0000 - val_loss: 3805223.2500\n",
      "Epoch 96/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3344750.0000 - val_loss: 3422092.7500\n",
      "Epoch 97/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2868949.0000 - val_loss: 3428979.2500\n",
      "Epoch 98/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3074691.2500 - val_loss: 3420714.7500\n",
      "Epoch 99/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3706863.0000 - val_loss: 3549915.2500\n",
      "Epoch 100/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3570976.7500 - val_loss: 3457298.2500\n",
      "Epoch 101/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3242831.7500 - val_loss: 3420360.0000\n",
      "Epoch 102/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3134686.7500 - val_loss: 3448402.0000\n",
      "Epoch 103/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3708103.7500 - val_loss: 3469472.7500\n",
      "Epoch 104/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3364655.0000 - val_loss: 3462178.7500\n",
      "Epoch 105/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3219900.0000 - val_loss: 3777848.2500\n",
      "Epoch 106/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2843036.7500 - val_loss: 3506271.0000\n",
      "Epoch 107/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2912519.0000 - val_loss: 3419838.2500\n",
      "Epoch 108/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2878050.2500 - val_loss: 3421926.0000\n",
      "Epoch 109/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3235775.7500 - val_loss: 3482773.2500\n",
      "Epoch 110/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3950771.7500 - val_loss: 4295456.5000\n",
      "Epoch 111/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3090970.7500 - val_loss: 3878405.0000\n",
      "Epoch 112/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2844098.2500 - val_loss: 3435012.0000\n",
      "Epoch 113/5000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 2897763.0000 - val_loss: 3530052.2500\n",
      "Epoch 114/5000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 3079587.7500 - val_loss: 3846430.0000\n",
      "Epoch 115/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3986405.7500 - val_loss: 3604044.0000\n",
      "Epoch 116/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4551329.5000 - val_loss: 5372479.5000\n",
      "Epoch 117/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3882328.2500 - val_loss: 3664901.2500\n",
      "Epoch 118/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4653129.5000 - val_loss: 5579246.0000\n",
      "Epoch 119/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4914112.5000 - val_loss: 4327629.0000\n",
      "Epoch 120/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3292613.0000 - val_loss: 3508889.2500\n",
      "Epoch 121/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2876851.7500 - val_loss: 3427521.2500\n",
      "Epoch 122/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2903437.0000 - val_loss: 3419418.7500\n",
      "Epoch 123/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3220616.2500 - val_loss: 3468221.7500\n",
      "Epoch 124/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3337076.7500 - val_loss: 4361954.0000\n",
      "Epoch 125/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4360408.5000 - val_loss: 3421639.2500\n",
      "Epoch 126/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3890831.7500 - val_loss: 3863157.7500\n",
      "Epoch 127/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3130506.2500 - val_loss: 4643253.5000\n",
      "Epoch 128/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3595226.0000 - val_loss: 3870042.2500\n",
      "Epoch 129/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4233424.0000 - val_loss: 5311448.0000\n",
      "Epoch 130/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3468651.2500 - val_loss: 4031746.2500\n",
      "Epoch 131/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3554273.7500 - val_loss: 3714610.7500\n",
      "Epoch 132/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3749565.0000 - val_loss: 3893763.0000\n",
      "Epoch 133/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4561480.0000 - val_loss: 4864730.0000\n",
      "Epoch 134/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4188573.2500 - val_loss: 3480216.0000\n",
      "Epoch 135/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3899125.7500 - val_loss: 3870207.7500\n",
      "Epoch 136/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3258296.2500 - val_loss: 3714152.7500\n",
      "Epoch 137/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3325108.7500 - val_loss: 3721998.0000\n",
      "Epoch 138/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3430815.7500 - val_loss: 4334014.5000\n",
      "Epoch 139/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4153204.2500 - val_loss: 3433251.7500\n",
      "Epoch 140/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4513360.0000 - val_loss: 3832921.2500\n",
      "Epoch 141/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3623640.7500 - val_loss: 3435438.0000\n",
      "Epoch 142/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3426292.7500 - val_loss: 4462994.0000\n",
      "Epoch 143/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4339457.5000 - val_loss: 3806814.7500\n",
      "Epoch 144/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3912465.0000 - val_loss: 3912333.2500\n",
      "Epoch 145/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3114024.0000 - val_loss: 3425955.0000\n",
      "Epoch 146/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3285070.7500 - val_loss: 3835196.0000\n",
      "Epoch 147/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3179403.2500 - val_loss: 3479439.7500\n",
      "Epoch 148/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2915906.0000 - val_loss: 3422586.0000\n",
      "Epoch 149/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2902942.7500 - val_loss: 3581806.2500\n",
      "Epoch 150/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3581782.0000 - val_loss: 4091846.7500\n",
      "Epoch 151/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3145686.7500 - val_loss: 3690731.2500\n",
      "Epoch 152/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3406110.7500 - val_loss: 3770288.7500\n",
      "Epoch 153/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3037426.0000 - val_loss: 3430263.2500\n",
      "Epoch 154/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3004574.7500 - val_loss: 3448472.2500\n",
      "Epoch 155/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2956316.0000 - val_loss: 3561021.0000\n",
      "Epoch 156/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4162031.0000 - val_loss: 5573400.0000\n",
      "Epoch 157/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7444078.5000 - val_loss: 7466782.0000\n",
      "Epoch 158/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5697219.5000 - val_loss: 3823557.2500\n",
      "Epoch 159/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4017780.0000 - val_loss: 7834759.5000\n",
      "Epoch 160/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7605755.5000 - val_loss: 3707828.0000\n",
      "Epoch 161/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5562807.5000 - val_loss: 8899719.0000\n",
      "Epoch 162/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5110358.5000 - val_loss: 6127606.0000\n",
      "Epoch 163/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4499350.5000 - val_loss: 3975624.0000\n",
      "Epoch 164/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3173219.0000 - val_loss: 3775314.2500\n",
      "Epoch 165/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3240488.7500 - val_loss: 3901976.7500\n",
      "Epoch 166/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2881482.7500 - val_loss: 3595901.2500\n",
      "Epoch 167/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2955812.0000 - val_loss: 4707980.0000\n",
      "Epoch 168/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3377966.2500 - val_loss: 3423049.2500\n",
      "Epoch 169/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2908312.7500 - val_loss: 3467733.2500\n",
      "Epoch 170/5000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 2865760.0000 - val_loss: 4046452.7500\n",
      "Epoch 171/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2908805.2500 - val_loss: 3934587.7500\n",
      "Epoch 172/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3147850.2500 - val_loss: 4647488.5000\n",
      "Epoch 173/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3563760.0000 - val_loss: 3475891.0000\n",
      "Epoch 174/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2962976.7500 - val_loss: 3914973.0000\n",
      "Epoch 175/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3257373.7500 - val_loss: 5432713.0000\n",
      "Epoch 176/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3870880.2500 - val_loss: 3651445.0000\n",
      "Epoch 177/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3715329.2500 - val_loss: 4694077.0000\n",
      "Epoch 178/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3234465.2500 - val_loss: 3889756.7500\n",
      "Epoch 179/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3329694.2500 - val_loss: 4303788.5000\n",
      "Epoch 180/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4741780.0000 - val_loss: 6949952.5000\n",
      "Epoch 181/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4683266.5000 - val_loss: 3881006.7500\n",
      "Epoch 182/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4301504.0000 - val_loss: 5568291.5000\n",
      "Epoch 183/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7759452.0000 - val_loss: 8047282.5000\n",
      "Epoch 184/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5179312.0000 - val_loss: 3445735.2500\n",
      "Epoch 185/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3230812.0000 - val_loss: 3491355.2500\n",
      "Epoch 186/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4207078.5000 - val_loss: 3416450.7500\n",
      "Epoch 187/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3806244.2500 - val_loss: 7081096.0000\n",
      "Epoch 188/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4380822.5000 - val_loss: 3441582.7500\n",
      "Epoch 189/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2903871.0000 - val_loss: 3485780.0000\n",
      "Epoch 190/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2811102.7500 - val_loss: 4566841.5000\n",
      "Epoch 191/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3050847.2500 - val_loss: 3597081.2500\n",
      "Epoch 192/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3209905.0000 - val_loss: 3544068.0000\n",
      "Epoch 193/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3727206.7500 - val_loss: 7897647.5000\n",
      "Epoch 194/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4847640.5000 - val_loss: 3443751.0000\n",
      "Epoch 195/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3295952.2500 - val_loss: 5465171.0000\n",
      "Epoch 196/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4669471.0000 - val_loss: 3804857.7500\n",
      "Epoch 197/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3728283.2500 - val_loss: 3914831.2500\n",
      "Epoch 198/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3225253.0000 - val_loss: 5286485.5000\n",
      "Epoch 199/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4850568.5000 - val_loss: 3696959.2500\n",
      "Epoch 200/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4901847.5000 - val_loss: 7876925.5000\n",
      "Epoch 201/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6091696.5000 - val_loss: 3438417.2500\n",
      "Epoch 202/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7987102.0000 - val_loss: 11083064.0000\n",
      "Epoch 203/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 7122842.0000 - val_loss: 6638145.5000\n",
      "Epoch 204/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5075435.0000 - val_loss: 4761793.0000\n",
      "Epoch 205/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3877705.2500 - val_loss: 3530801.2500\n",
      "Epoch 206/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3495996.0000 - val_loss: 3607466.7500\n",
      "Epoch 207/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5920374.5000 - val_loss: 8454431.0000\n",
      "Epoch 208/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4715514.0000 - val_loss: 3686541.7500\n",
      "Epoch 209/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4342200.5000 - val_loss: 4591496.5000\n",
      "Epoch 210/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4753813.5000 - val_loss: 5434142.5000\n",
      "Epoch 211/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4239164.5000 - val_loss: 3958070.0000\n",
      "Epoch 212/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3423946.7500 - val_loss: 3440610.7500\n",
      "Epoch 213/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4123186.0000 - val_loss: 3536392.0000\n",
      "Epoch 214/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4099066.7500 - val_loss: 7083197.5000\n",
      "Epoch 215/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5937011.5000 - val_loss: 3553366.7500\n",
      "Epoch 216/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4697007.5000 - val_loss: 7002093.5000\n",
      "Epoch 217/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5132792.5000 - val_loss: 3699746.0000\n",
      "Epoch 218/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5875962.0000 - val_loss: 5844834.5000\n",
      "Epoch 219/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5365078.5000 - val_loss: 3740490.2500\n",
      "Epoch 220/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5119222.0000 - val_loss: 9726327.0000\n",
      "Epoch 221/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6205946.5000 - val_loss: 3736183.7500\n",
      "Epoch 222/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4056399.2500 - val_loss: 3504729.0000\n",
      "Epoch 223/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2929236.0000 - val_loss: 4855307.5000\n",
      "Epoch 224/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3473308.0000 - val_loss: 3691129.0000\n",
      "Epoch 225/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3260664.0000 - val_loss: 3439439.7500\n",
      "Epoch 226/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3707744.7500 - val_loss: 4247564.5000\n",
      "Epoch 227/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3134775.0000 - val_loss: 4383835.5000\n",
      "Epoch 228/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4446189.0000 - val_loss: 6704529.5000\n",
      "Epoch 229/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4058608.7500 - val_loss: 3818107.2500\n",
      "Epoch 230/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3255176.7500 - val_loss: 4533590.0000\n",
      "Epoch 231/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3049066.7500 - val_loss: 3473318.2500\n",
      "Epoch 232/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3209336.0000 - val_loss: 3418248.7500\n",
      "Epoch 233/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3290044.0000 - val_loss: 3571627.2500\n",
      "Epoch 234/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3196696.0000 - val_loss: 3522680.0000\n",
      "Epoch 235/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3016758.2500 - val_loss: 3429854.7500\n",
      "Epoch 236/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2994399.7500 - val_loss: 3859116.0000\n",
      "Epoch 237/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3698277.2500 - val_loss: 5076999.0000\n",
      "Epoch 238/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3982441.7500 - val_loss: 4107601.2500\n",
      "Epoch 239/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5179973.5000 - val_loss: 7666266.5000\n",
      "Epoch 240/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6653693.5000 - val_loss: 4310492.5000\n",
      "Epoch 241/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5138104.5000 - val_loss: 8936233.0000\n",
      "Epoch 242/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 6354870.5000 - val_loss: 3619116.0000\n",
      "Epoch 243/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3734502.2500 - val_loss: 4704460.0000\n",
      "Epoch 244/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3721509.2500 - val_loss: 3786770.0000\n",
      "Epoch 245/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3245914.2500 - val_loss: 3649560.7500\n",
      "Epoch 246/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3198717.7500 - val_loss: 3477041.7500\n",
      "Epoch 247/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3182892.2500 - val_loss: 4461439.5000\n",
      "Epoch 248/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3545050.0000 - val_loss: 4129010.7500\n",
      "Epoch 249/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3366168.0000 - val_loss: 3758941.2500\n",
      "Epoch 250/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3434945.0000 - val_loss: 4542954.0000\n",
      "Epoch 251/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3667607.2500 - val_loss: 3605908.0000\n",
      "Epoch 252/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3340153.7500 - val_loss: 3574006.0000\n",
      "Epoch 253/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3408772.7500 - val_loss: 3814092.7500\n",
      "Epoch 254/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3117596.2500 - val_loss: 3714668.0000\n",
      "Epoch 255/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3329279.7500 - val_loss: 3419740.7500\n",
      "Epoch 256/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3206694.0000 - val_loss: 4570522.0000\n",
      "Epoch 257/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4045020.7500 - val_loss: 3652020.0000\n",
      "Epoch 258/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3255656.2500 - val_loss: 3439874.0000\n",
      "Epoch 259/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3959338.2500 - val_loss: 4229435.0000\n",
      "Epoch 260/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3726284.7500 - val_loss: 4017246.7500\n",
      "Epoch 261/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4787728.0000 - val_loss: 5959804.0000\n",
      "Epoch 262/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 6162655.5000 - val_loss: 6715386.0000\n",
      "Epoch 263/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4118944.7500 - val_loss: 3470578.0000\n",
      "Epoch 264/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3584576.7500 - val_loss: 7481276.0000\n",
      "Epoch 265/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6453262.5000 - val_loss: 3574739.0000\n",
      "Epoch 266/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6145242.5000 - val_loss: 7574990.5000\n",
      "Epoch 267/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6662140.0000 - val_loss: 6424982.0000\n",
      "Epoch 268/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6455980.0000 - val_loss: 5182925.0000\n",
      "Epoch 269/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4389311.5000 - val_loss: 5826909.5000\n",
      "Epoch 270/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4791164.0000 - val_loss: 7415288.0000\n",
      "Epoch 271/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5601854.0000 - val_loss: 6048334.5000\n",
      "Epoch 272/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5482064.5000 - val_loss: 7461556.0000\n",
      "Epoch 273/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4723587.0000 - val_loss: 5893144.0000\n",
      "Epoch 274/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4524418.5000 - val_loss: 3432797.0000\n",
      "Epoch 275/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4093388.2500 - val_loss: 5736440.5000\n",
      "Epoch 276/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3882930.7500 - val_loss: 4198939.5000\n",
      "Epoch 277/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3362799.2500 - val_loss: 3556996.0000\n",
      "Epoch 278/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4906949.5000 - val_loss: 5485148.5000\n",
      "Epoch 279/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3219436.7500 - val_loss: 5340390.5000\n",
      "Epoch 280/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3688991.0000 - val_loss: 3463156.0000\n",
      "Epoch 281/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3081772.7500 - val_loss: 3922042.7500\n",
      "Epoch 282/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3846136.0000 - val_loss: 4716128.5000\n",
      "Epoch 283/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3935454.7500 - val_loss: 4425189.0000\n",
      "Epoch 284/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3111045.7500 - val_loss: 3836223.2500\n",
      "Epoch 285/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3126204.2500 - val_loss: 3521595.0000\n",
      "Epoch 286/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3813504.7500 - val_loss: 5473496.5000\n",
      "Epoch 287/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3563795.0000 - val_loss: 3565840.7500\n",
      "Epoch 288/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2835806.7500 - val_loss: 3624886.0000\n",
      "Epoch 289/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3456502.0000 - val_loss: 6751436.5000\n",
      "Epoch 290/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5884518.0000 - val_loss: 3710242.0000\n",
      "Epoch 291/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4257279.5000 - val_loss: 4105308.0000\n",
      "Epoch 292/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3276165.0000 - val_loss: 4597555.5000\n",
      "Epoch 293/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4023731.0000 - val_loss: 3807965.7500\n",
      "Epoch 294/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3257536.0000 - val_loss: 4170139.0000\n",
      "Epoch 295/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3287237.7500 - val_loss: 3420493.7500\n",
      "Epoch 296/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3522895.0000 - val_loss: 5092879.5000\n",
      "Epoch 297/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3747214.0000 - val_loss: 5921582.0000\n",
      "Epoch 298/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4579140.5000 - val_loss: 4318528.0000\n",
      "Epoch 299/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 5761676.0000 - val_loss: 11720427.0000\n",
      "Epoch 300/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 8436925.0000 - val_loss: 3576429.2500\n",
      "Epoch 301/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5457090.5000 - val_loss: 8013841.5000\n",
      "Epoch 302/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6465312.0000 - val_loss: 3593614.7500\n",
      "Epoch 303/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5370689.5000 - val_loss: 5439496.0000\n",
      "Epoch 304/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3804453.0000 - val_loss: 4532573.5000\n",
      "Epoch 305/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3702049.2500 - val_loss: 6479937.5000\n",
      "Epoch 306/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3903888.0000 - val_loss: 4071767.2500\n",
      "Epoch 307/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3373595.0000 - val_loss: 3515734.0000\n",
      "Epoch 308/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3017751.7500 - val_loss: 4059806.7500\n",
      "Epoch 309/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4168983.0000 - val_loss: 3424612.0000\n",
      "Epoch 310/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4356043.5000 - val_loss: 4495012.5000\n",
      "Epoch 311/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3830811.7500 - val_loss: 3483836.2500\n",
      "Epoch 312/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3734677.0000 - val_loss: 6814237.5000\n",
      "Epoch 313/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4706086.5000 - val_loss: 3410783.2500\n",
      "Epoch 314/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3101915.2500 - val_loss: 3489734.2500\n",
      "Epoch 315/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3067035.2500 - val_loss: 3838370.2500\n",
      "Epoch 316/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3150130.7500 - val_loss: 3543691.0000\n",
      "Epoch 317/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3000467.2500 - val_loss: 4736984.0000\n",
      "Epoch 318/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3501198.0000 - val_loss: 3932204.7500\n",
      "Epoch 319/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3642817.2500 - val_loss: 3437269.2500\n",
      "Epoch 320/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3177366.0000 - val_loss: 3606259.7500\n",
      "Epoch 321/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3262647.2500 - val_loss: 3414128.7500\n",
      "Epoch 322/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3457305.0000 - val_loss: 3695060.7500\n",
      "Epoch 323/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4583834.0000 - val_loss: 3488750.0000\n",
      "Epoch 324/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3698245.0000 - val_loss: 3411637.0000\n",
      "Epoch 325/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4036889.0000 - val_loss: 5858664.5000\n",
      "Epoch 326/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5649460.0000 - val_loss: 3453090.7500\n",
      "Epoch 327/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4601380.0000 - val_loss: 5103732.5000\n",
      "Epoch 328/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4372206.5000 - val_loss: 3520761.2500\n",
      "Epoch 329/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4783663.5000 - val_loss: 5524495.5000\n",
      "Epoch 330/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4107342.2500 - val_loss: 4390978.5000\n",
      "Epoch 331/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3891297.7500 - val_loss: 7057078.5000\n",
      "Epoch 332/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6932251.5000 - val_loss: 4569694.0000\n",
      "Epoch 333/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6196680.0000 - val_loss: 16398353.0000\n",
      "Epoch 334/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 8783567.0000 - val_loss: 3462493.2500\n",
      "Epoch 335/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3859319.7500 - val_loss: 3556356.7500\n",
      "Epoch 336/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4108280.0000 - val_loss: 6302506.0000\n",
      "Epoch 337/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3515182.0000 - val_loss: 3886658.7500\n",
      "Epoch 338/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3492684.7500 - val_loss: 4028898.0000\n",
      "Epoch 339/5000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3156667.2500 - val_loss: 3656346.0000\n",
      "Epoch 340/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3079297.7500 - val_loss: 3434297.2500\n",
      "Epoch 341/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3344938.7500 - val_loss: 3439043.2500\n",
      "Epoch 342/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3727694.7500 - val_loss: 3743968.0000\n",
      "Epoch 343/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3515418.0000 - val_loss: 6666741.5000\n",
      "Epoch 344/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6033168.0000 - val_loss: 5357088.0000\n",
      "Epoch 345/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4192256.7500 - val_loss: 3950501.7500\n",
      "Epoch 346/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3036805.0000 - val_loss: 3598931.2500\n",
      "Epoch 347/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3010958.0000 - val_loss: 3852901.0000\n",
      "Epoch 348/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3254075.7500 - val_loss: 3707572.2500\n",
      "Epoch 349/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3402095.7500 - val_loss: 3409641.0000\n",
      "Epoch 350/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3250385.2500 - val_loss: 4709983.0000\n",
      "Epoch 351/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3294752.7500 - val_loss: 3423103.7500\n",
      "Epoch 352/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2854782.0000 - val_loss: 3801147.7500\n",
      "Epoch 353/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2975449.2500 - val_loss: 3434658.7500\n",
      "Epoch 354/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3235477.0000 - val_loss: 3962714.0000\n",
      "Epoch 355/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3272842.2500 - val_loss: 3409329.7500\n",
      "Epoch 356/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3078060.0000 - val_loss: 3767479.0000\n",
      "Epoch 357/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3236086.2500 - val_loss: 4993487.5000\n",
      "Epoch 358/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4284571.5000 - val_loss: 5313481.5000\n",
      "Epoch 359/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3628944.0000 - val_loss: 3428348.0000\n",
      "Epoch 360/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3170113.7500 - val_loss: 4195454.5000\n",
      "Epoch 361/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4230314.5000 - val_loss: 6549822.0000\n",
      "Epoch 362/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4774807.5000 - val_loss: 3855027.0000\n",
      "Epoch 363/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3924545.2500 - val_loss: 5259282.5000\n",
      "Epoch 364/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6558486.5000 - val_loss: 3853568.7500\n",
      "Epoch 365/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5922525.5000 - val_loss: 8907553.0000\n",
      "Epoch 366/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5654386.0000 - val_loss: 4681426.0000\n",
      "Epoch 367/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4852186.5000 - val_loss: 4589578.5000\n",
      "Epoch 368/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3291238.2500 - val_loss: 3539979.0000\n",
      "Epoch 369/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3152044.2500 - val_loss: 3774118.7500\n",
      "Epoch 370/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3302948.0000 - val_loss: 3470985.0000\n",
      "Epoch 371/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3216008.0000 - val_loss: 3456191.7500\n",
      "Epoch 372/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3251142.2500 - val_loss: 3496816.0000\n",
      "Epoch 373/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3250726.7500 - val_loss: 3467138.7500\n",
      "Epoch 374/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3070945.2500 - val_loss: 3537582.0000\n",
      "Epoch 375/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3432428.2500 - val_loss: 5045412.5000\n",
      "Epoch 376/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3294913.2500 - val_loss: 5249050.5000\n",
      "Epoch 377/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3439668.2500 - val_loss: 4866714.5000\n",
      "Epoch 378/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5519876.5000 - val_loss: 4468759.5000\n",
      "Epoch 379/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3977874.7500 - val_loss: 5772659.5000\n",
      "Epoch 380/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4630691.5000 - val_loss: 3412402.0000\n",
      "Epoch 381/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3393844.0000 - val_loss: 4564377.5000\n",
      "Epoch 382/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3105383.7500 - val_loss: 4709884.0000\n",
      "Epoch 383/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3450895.7500 - val_loss: 4107105.7500\n",
      "Epoch 384/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3570790.2500 - val_loss: 4160262.7500\n",
      "Epoch 385/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3919702.2500 - val_loss: 9493915.0000\n",
      "Epoch 386/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5563565.0000 - val_loss: 3422273.2500\n",
      "Epoch 387/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5377912.5000 - val_loss: 6988957.5000\n",
      "Epoch 388/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4544422.5000 - val_loss: 4720930.5000\n",
      "Epoch 389/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3933913.2500 - val_loss: 4917759.5000\n",
      "Epoch 390/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3580813.7500 - val_loss: 3851775.7500\n",
      "Epoch 391/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4799616.5000 - val_loss: 3744672.0000\n",
      "Epoch 392/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4519424.0000 - val_loss: 7657374.0000\n",
      "Epoch 393/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4625122.0000 - val_loss: 3826219.2500\n",
      "Epoch 394/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3222838.0000 - val_loss: 3407016.7500\n",
      "Epoch 395/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3130738.0000 - val_loss: 4251927.5000\n",
      "Epoch 396/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2990276.7500 - val_loss: 3430543.2500\n",
      "Epoch 397/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3100215.7500 - val_loss: 3450530.7500\n",
      "Epoch 398/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3065897.0000 - val_loss: 3602013.2500\n",
      "Epoch 399/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3342803.2500 - val_loss: 3559044.7500\n",
      "Epoch 400/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3541140.7500 - val_loss: 3983869.2500\n",
      "Epoch 401/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3287980.2500 - val_loss: 3917036.0000\n",
      "Epoch 402/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3233321.2500 - val_loss: 4409392.5000\n",
      "Epoch 403/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3975944.7500 - val_loss: 3418922.0000\n",
      "Epoch 404/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5431821.5000 - val_loss: 9204713.0000\n",
      "Epoch 405/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6953057.5000 - val_loss: 4069083.0000\n",
      "Epoch 406/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5243447.0000 - val_loss: 4633282.5000\n",
      "Epoch 407/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3067247.2500 - val_loss: 3651019.7500\n",
      "Epoch 408/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3616775.7500 - val_loss: 3485108.7500\n",
      "Epoch 409/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4263548.5000 - val_loss: 5814467.5000\n",
      "Epoch 410/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4550392.5000 - val_loss: 7149617.5000\n",
      "Epoch 411/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4590078.5000 - val_loss: 3567914.7500\n",
      "Epoch 412/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3387209.2500 - val_loss: 3859874.0000\n",
      "Epoch 413/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3252913.2500 - val_loss: 4928708.5000\n",
      "Epoch 414/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3350401.0000 - val_loss: 3771317.2500\n",
      "Epoch 415/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3158802.7500 - val_loss: 3522543.0000\n",
      "Epoch 416/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2863394.7500 - val_loss: 5081332.5000\n",
      "Epoch 417/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4388009.5000 - val_loss: 3444167.2500\n",
      "Epoch 418/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5526682.5000 - val_loss: 5452872.5000\n",
      "Epoch 419/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4027903.2500 - val_loss: 4613665.0000\n",
      "Epoch 420/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4354794.0000 - val_loss: 4420137.5000\n",
      "Epoch 421/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4481311.5000 - val_loss: 5717346.0000\n",
      "Epoch 422/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3965441.2500 - val_loss: 3410373.2500\n",
      "Epoch 423/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3247988.0000 - val_loss: 7160272.0000\n",
      "Epoch 424/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3891475.0000 - val_loss: 4624743.5000\n",
      "Epoch 425/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3716134.0000 - val_loss: 3652729.2500\n",
      "Epoch 426/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2890530.7500 - val_loss: 3441829.2500\n",
      "Epoch 427/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2848088.0000 - val_loss: 3409200.7500\n",
      "Epoch 428/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3498893.0000 - val_loss: 4489804.5000\n",
      "Epoch 429/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4190810.7500 - val_loss: 7235569.5000\n",
      "Epoch 430/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 4783818.5000 - val_loss: 4825365.0000\n",
      "Epoch 431/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3686471.7500 - val_loss: 3541664.0000\n",
      "Epoch 432/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3531288.0000 - val_loss: 3828882.7500\n",
      "Epoch 433/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3646386.2500 - val_loss: 3412190.0000\n",
      "Epoch 434/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5008324.5000 - val_loss: 3652224.7500\n",
      "Epoch 435/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4032027.2500 - val_loss: 8560405.0000\n",
      "Epoch 436/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5857777.5000 - val_loss: 3729826.7500\n",
      "Epoch 437/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5236364.5000 - val_loss: 6310281.5000\n",
      "Epoch 438/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4786832.0000 - val_loss: 3980643.7500\n",
      "Epoch 439/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3263263.7500 - val_loss: 3639702.7500\n",
      "Epoch 440/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3503094.2500 - val_loss: 4762723.5000\n",
      "Epoch 441/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3560739.2500 - val_loss: 3473149.2500\n",
      "Epoch 442/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3932374.0000 - val_loss: 3968418.7500\n",
      "Epoch 443/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3319600.0000 - val_loss: 3408035.2500\n",
      "Epoch 444/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2912449.2500 - val_loss: 3418000.2500\n",
      "Epoch 445/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3529382.7500 - val_loss: 3599742.0000\n",
      "Epoch 446/5000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 3863133.2500 - val_loss: 8353721.5000\n",
      "Epoch 447/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 5859596.5000 - val_loss: 3540802.0000\n",
      "Epoch 448/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3781167.7500 - val_loss: 3952186.0000\n",
      "Epoch 449/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4093391.0000 - val_loss: 4161370.0000\n",
      "Epoch 450/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4577513.0000 - val_loss: 5403073.5000\n",
      "Epoch 451/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3324243.2500 - val_loss: 4533299.5000\n",
      "Epoch 452/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4069245.2500 - val_loss: 3420389.2500\n",
      "Epoch 453/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3859942.2500 - val_loss: 6528554.0000\n",
      "Epoch 454/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3741362.2500 - val_loss: 3880005.2500\n",
      "Epoch 455/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3245668.0000 - val_loss: 4516107.5000\n",
      "Epoch 456/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3473840.0000 - val_loss: 4159649.2500\n",
      "Epoch 457/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3017037.7500 - val_loss: 3791538.7500\n",
      "Epoch 458/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3646210.2500 - val_loss: 5273892.5000\n",
      "Epoch 459/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4379491.5000 - val_loss: 4256450.0000\n",
      "Epoch 460/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4964213.0000 - val_loss: 4477768.0000\n",
      "Epoch 461/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5676172.0000 - val_loss: 8655350.0000\n",
      "Epoch 462/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5282799.5000 - val_loss: 3535755.7500\n",
      "Epoch 463/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 6606838.5000 - val_loss: 9426999.0000\n",
      "Epoch 464/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5479811.5000 - val_loss: 3433118.2500\n",
      "Epoch 465/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4376707.5000 - val_loss: 7463782.0000\n",
      "Epoch 466/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5261727.0000 - val_loss: 4967394.5000\n",
      "Epoch 467/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2948950.0000 - val_loss: 3816202.2500\n",
      "Epoch 468/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3305148.7500 - val_loss: 3617597.7500\n",
      "Epoch 469/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2916556.0000 - val_loss: 3620144.7500\n",
      "Epoch 470/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4118477.2500 - val_loss: 4124902.2500\n",
      "Epoch 471/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4699615.0000 - val_loss: 5517628.5000\n",
      "Epoch 472/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4387535.5000 - val_loss: 5288436.0000\n",
      "Epoch 473/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5137433.0000 - val_loss: 4083427.2500\n",
      "Epoch 474/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3518480.7500 - val_loss: 3860875.7500\n",
      "Epoch 475/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2911902.0000 - val_loss: 3653604.0000\n",
      "Epoch 476/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2875760.7500 - val_loss: 3404494.7500\n",
      "Epoch 477/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2911666.7500 - val_loss: 3481198.2500\n",
      "Epoch 478/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3412888.0000 - val_loss: 4067258.7500\n",
      "Epoch 479/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 4485569.5000 - val_loss: 5847557.5000\n",
      "Epoch 480/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 6305156.5000 - val_loss: 4863975.5000\n",
      "Epoch 481/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4527747.5000 - val_loss: 4631254.5000\n",
      "Epoch 482/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6165948.5000 - val_loss: 8212469.5000\n",
      "Epoch 483/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5372935.5000 - val_loss: 3421766.7500\n",
      "Epoch 484/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4510717.5000 - val_loss: 8190028.5000\n",
      "Epoch 485/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5987120.5000 - val_loss: 4165499.2500\n",
      "Epoch 486/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4569941.0000 - val_loss: 5660072.0000\n",
      "Epoch 487/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4718601.5000 - val_loss: 3448350.7500\n",
      "Epoch 488/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3429357.7500 - val_loss: 3484731.0000\n",
      "Epoch 489/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3547600.2500 - val_loss: 6206261.5000\n",
      "Epoch 490/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3857743.2500 - val_loss: 3606918.0000\n",
      "Epoch 491/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3284311.2500 - val_loss: 3425182.7500\n",
      "Epoch 492/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3128780.0000 - val_loss: 5118077.5000\n",
      "Epoch 493/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3828314.7500 - val_loss: 3411466.7500\n",
      "Epoch 494/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4909538.0000 - val_loss: 6282412.5000\n",
      "Epoch 495/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5200860.5000 - val_loss: 4217826.5000\n",
      "Epoch 496/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4231954.0000 - val_loss: 4247498.0000\n",
      "Epoch 497/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3917400.7500 - val_loss: 8459243.0000\n",
      "Epoch 498/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4071179.2500 - val_loss: 3418299.0000\n",
      "Epoch 499/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3044333.2500 - val_loss: 3523098.0000\n",
      "Epoch 500/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3648495.2500 - val_loss: 3480735.7500\n",
      "Epoch 501/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5970505.5000 - val_loss: 11708560.0000\n",
      "Epoch 502/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6722024.0000 - val_loss: 3689644.2500\n",
      "Epoch 503/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3788234.7500 - val_loss: 4386877.5000\n",
      "Epoch 504/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3900094.2500 - val_loss: 4435746.0000\n",
      "Epoch 505/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4270910.5000 - val_loss: 3412746.7500\n",
      "Epoch 506/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3732720.7500 - val_loss: 7624553.5000\n",
      "Epoch 507/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4164036.2500 - val_loss: 7699179.5000\n",
      "Epoch 508/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5181448.5000 - val_loss: 4305734.5000\n",
      "Epoch 509/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3697356.2500 - val_loss: 4484099.5000\n",
      "Epoch 510/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3107095.2500 - val_loss: 4198381.0000\n",
      "Epoch 511/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3073331.7500 - val_loss: 3462505.7500\n",
      "Epoch 512/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2960497.0000 - val_loss: 3425593.7500\n",
      "Epoch 513/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2939677.2500 - val_loss: 3574631.2500\n",
      "Epoch 514/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3574118.0000 - val_loss: 3812256.0000\n",
      "Epoch 515/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4000024.0000 - val_loss: 3873216.7500\n",
      "Epoch 516/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4054168.2500 - val_loss: 9013191.0000\n",
      "Epoch 517/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4554448.0000 - val_loss: 3544104.2500\n",
      "Epoch 518/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3748082.7500 - val_loss: 6362865.5000\n",
      "Epoch 519/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4965146.5000 - val_loss: 4365519.0000\n",
      "Epoch 520/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3318884.2500 - val_loss: 3539213.7500\n",
      "Epoch 521/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2890097.0000 - val_loss: 3633907.2500\n",
      "Epoch 522/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3130614.7500 - val_loss: 3639973.2500\n",
      "Epoch 523/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3071658.7500 - val_loss: 3407923.0000\n",
      "Epoch 524/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2984689.7500 - val_loss: 4415753.5000\n",
      "Epoch 525/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3710597.0000 - val_loss: 4322136.0000\n",
      "Epoch 526/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4310616.5000 - val_loss: 3781884.2500\n",
      "Epoch 527/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2959347.2500 - val_loss: 3493279.0000\n",
      "Epoch 528/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3658349.7500 - val_loss: 4476072.0000\n",
      "Epoch 529/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3398692.2500 - val_loss: 4196798.5000\n",
      "Epoch 530/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3299835.2500 - val_loss: 3418203.2500\n",
      "Epoch 531/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2987285.0000 - val_loss: 3528526.2500\n",
      "Epoch 532/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2998046.0000 - val_loss: 3739836.2500\n",
      "Epoch 533/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2929535.0000 - val_loss: 3837823.0000\n",
      "Epoch 534/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3330776.0000 - val_loss: 3403530.0000\n",
      "Epoch 535/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3166654.0000 - val_loss: 3686748.0000\n",
      "Epoch 536/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3032522.7500 - val_loss: 5113597.0000\n",
      "Epoch 537/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4104584.0000 - val_loss: 3892590.7500\n",
      "Epoch 538/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4132869.0000 - val_loss: 4172279.0000\n",
      "Epoch 539/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3846193.2500 - val_loss: 5737728.5000\n",
      "Epoch 540/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3898778.7500 - val_loss: 5476838.0000\n",
      "Epoch 541/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5523107.5000 - val_loss: 3410333.2500\n",
      "Epoch 542/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4223654.5000 - val_loss: 4084739.7500\n",
      "Epoch 543/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3071612.0000 - val_loss: 3893374.0000\n",
      "Epoch 544/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3238302.7500 - val_loss: 5266705.5000\n",
      "Epoch 545/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3322286.7500 - val_loss: 5730252.0000\n",
      "Epoch 546/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4388313.0000 - val_loss: 3543695.2500\n",
      "Epoch 547/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2999810.2500 - val_loss: 3489930.0000\n",
      "Epoch 548/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3169358.0000 - val_loss: 3753073.7500\n",
      "Epoch 549/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3363378.7500 - val_loss: 3478157.0000\n",
      "Epoch 550/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3136935.0000 - val_loss: 3441874.2500\n",
      "Epoch 551/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3316852.0000 - val_loss: 4002833.0000\n",
      "Epoch 552/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3048260.0000 - val_loss: 3512668.0000\n",
      "Epoch 553/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3256005.0000 - val_loss: 3480339.2500\n",
      "Epoch 554/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3537538.7500 - val_loss: 5144240.5000\n",
      "Epoch 555/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4085447.2500 - val_loss: 3404537.0000\n",
      "Epoch 556/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3871305.2500 - val_loss: 5807768.5000\n",
      "Epoch 557/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4409206.5000 - val_loss: 4499942.0000\n",
      "Epoch 558/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3087708.7500 - val_loss: 3704040.7500\n",
      "Epoch 559/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2877400.0000 - val_loss: 3413350.2500\n",
      "Epoch 560/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2934544.0000 - val_loss: 3992429.2500\n",
      "Epoch 561/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3694756.0000 - val_loss: 6342315.5000\n",
      "Epoch 562/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4226319.0000 - val_loss: 3934127.0000\n",
      "Epoch 563/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3773031.2500 - val_loss: 6615004.0000\n",
      "Epoch 564/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3571774.7500 - val_loss: 3424028.0000\n",
      "Epoch 565/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3260273.7500 - val_loss: 3824664.7500\n",
      "Epoch 566/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3146120.0000 - val_loss: 5534608.5000\n",
      "Epoch 567/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3904027.2500 - val_loss: 3400543.0000\n",
      "Epoch 568/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3121927.2500 - val_loss: 3400885.2500\n",
      "Epoch 569/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2916530.7500 - val_loss: 3870496.2500\n",
      "Epoch 570/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2908876.7500 - val_loss: 3429868.0000\n",
      "Epoch 571/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2788827.5000 - val_loss: 3447824.0000\n",
      "Epoch 572/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2794342.7500 - val_loss: 3486084.0000\n",
      "Epoch 573/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2965570.7500 - val_loss: 3400429.0000\n",
      "Epoch 574/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3306096.2500 - val_loss: 3563086.2500\n",
      "Epoch 575/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3524016.0000 - val_loss: 4207262.0000\n",
      "Epoch 576/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4004461.7500 - val_loss: 7491544.0000\n",
      "Epoch 577/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4734326.5000 - val_loss: 3992041.0000\n",
      "Epoch 578/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3540615.0000 - val_loss: 5025835.5000\n",
      "Epoch 579/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3728385.7500 - val_loss: 3516353.2500\n",
      "Epoch 580/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3447915.2500 - val_loss: 4529877.5000\n",
      "Epoch 581/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3995025.7500 - val_loss: 3415898.7500\n",
      "Epoch 582/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4626616.5000 - val_loss: 3943813.2500\n",
      "Epoch 583/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3914590.7500 - val_loss: 4505939.5000\n",
      "Epoch 584/5000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 3930321.2500 - val_loss: 5562771.5000\n",
      "Epoch 585/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4729614.5000 - val_loss: 3895502.2500\n",
      "Epoch 586/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3501791.7500 - val_loss: 4654024.0000\n",
      "Epoch 587/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3691149.0000 - val_loss: 5215840.5000\n",
      "Epoch 588/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3743659.2500 - val_loss: 3593075.7500\n",
      "Epoch 589/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3353762.2500 - val_loss: 5328438.0000\n",
      "Epoch 590/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4082138.7500 - val_loss: 3456087.2500\n",
      "Epoch 591/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3986680.2500 - val_loss: 9515284.0000\n",
      "Epoch 592/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6425809.5000 - val_loss: 3420932.0000\n",
      "Epoch 593/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6767809.5000 - val_loss: 6241803.5000\n",
      "Epoch 594/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5018895.5000 - val_loss: 3662147.0000\n",
      "Epoch 595/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3292382.7500 - val_loss: 3943301.2500\n",
      "Epoch 596/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3455361.0000 - val_loss: 3830056.0000\n",
      "Epoch 597/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3691169.0000 - val_loss: 4073762.7500\n",
      "Epoch 598/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3667279.2500 - val_loss: 4778605.5000\n",
      "Epoch 599/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3680088.0000 - val_loss: 5685884.5000\n",
      "Epoch 600/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3659690.0000 - val_loss: 3539111.2500\n",
      "Epoch 601/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3372142.2500 - val_loss: 3729169.2500\n",
      "Epoch 602/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3142459.0000 - val_loss: 3783951.2500\n",
      "Epoch 603/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3211022.7500 - val_loss: 3613068.2500\n",
      "Epoch 604/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4059709.0000 - val_loss: 5528864.5000\n",
      "Epoch 605/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4160181.7500 - val_loss: 3398565.2500\n",
      "Epoch 606/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3213717.7500 - val_loss: 3679574.7500\n",
      "Epoch 607/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3289391.2500 - val_loss: 3604757.7500\n",
      "Epoch 608/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2781825.5000 - val_loss: 3405820.0000\n",
      "Epoch 609/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2928472.7500 - val_loss: 3681462.0000\n",
      "Epoch 610/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2988133.7500 - val_loss: 3470458.7500\n",
      "Epoch 611/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3134017.2500 - val_loss: 3430227.0000\n",
      "Epoch 612/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3159847.0000 - val_loss: 3595005.2500\n",
      "Epoch 613/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3097610.7500 - val_loss: 3423559.7500\n",
      "Epoch 614/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2815187.0000 - val_loss: 4738469.0000\n",
      "Epoch 615/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3946156.7500 - val_loss: 3404897.7500\n",
      "Epoch 616/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3255039.0000 - val_loss: 3519542.0000\n",
      "Epoch 617/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3139602.2500 - val_loss: 3722264.7500\n",
      "Epoch 618/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3266863.7500 - val_loss: 4370459.5000\n",
      "Epoch 619/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3102246.0000 - val_loss: 3504021.0000\n",
      "Epoch 620/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2932064.2500 - val_loss: 4861496.0000\n",
      "Epoch 621/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4069012.7500 - val_loss: 3637847.7500\n",
      "Epoch 622/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4171623.2500 - val_loss: 6408121.5000\n",
      "Epoch 623/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 5137096.0000 - val_loss: 4993445.5000\n",
      "Epoch 624/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4311173.5000 - val_loss: 3730197.0000\n",
      "Epoch 625/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2742647.7500 - val_loss: 6212924.0000\n",
      "Epoch 626/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 3560510.7500 - val_loss: 5095048.0000\n",
      "Epoch 627/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3262942.0000 - val_loss: 3645646.7500\n",
      "Epoch 628/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3259094.0000 - val_loss: 3862928.0000\n",
      "Epoch 629/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3415911.2500 - val_loss: 3577054.7500\n",
      "Epoch 630/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3349365.2500 - val_loss: 4139747.2500\n",
      "Epoch 631/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3782388.7500 - val_loss: 3549168.2500\n",
      "Epoch 632/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3508699.0000 - val_loss: 4871236.0000\n",
      "Epoch 633/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4820788.0000 - val_loss: 4251863.0000\n",
      "Epoch 634/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4473898.5000 - val_loss: 7303348.0000\n",
      "Epoch 635/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5536330.5000 - val_loss: 5516383.5000\n",
      "Epoch 636/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3238840.2500 - val_loss: 3820640.2500\n",
      "Epoch 637/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4669601.5000 - val_loss: 5799238.5000\n",
      "Epoch 638/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4978636.5000 - val_loss: 3490656.0000\n",
      "Epoch 639/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4694617.5000 - val_loss: 6780567.5000\n",
      "Epoch 640/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4253324.5000 - val_loss: 3642890.7500\n",
      "Epoch 641/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 4140751.0000 - val_loss: 3411249.7500\n",
      "Epoch 642/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3425970.7500 - val_loss: 5509037.5000\n",
      "Epoch 643/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3699145.2500 - val_loss: 3439622.2500\n",
      "Epoch 644/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3006353.7500 - val_loss: 3834964.2500\n",
      "Epoch 645/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4593494.5000 - val_loss: 4530743.5000\n",
      "Epoch 646/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3726573.7500 - val_loss: 3403926.0000\n",
      "Epoch 647/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3119859.0000 - val_loss: 3584394.7500\n",
      "Epoch 648/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3063203.0000 - val_loss: 4285740.0000\n",
      "Epoch 649/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3529646.7500 - val_loss: 4559184.5000\n",
      "Epoch 650/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3893946.7500 - val_loss: 4525689.5000\n",
      "Epoch 651/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5326669.0000 - val_loss: 4181739.2500\n",
      "Epoch 652/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3119529.0000 - val_loss: 3567058.7500\n",
      "Epoch 653/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3164812.2500 - val_loss: 5084078.5000\n",
      "Epoch 654/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3419369.0000 - val_loss: 3427375.0000\n",
      "Epoch 655/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3032764.7500 - val_loss: 5335986.0000\n",
      "Epoch 656/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4238425.0000 - val_loss: 3442981.0000\n",
      "Epoch 657/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 4502988.0000 - val_loss: 4378988.5000\n",
      "Epoch 658/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4188234.2500 - val_loss: 5742264.0000\n",
      "Epoch 659/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4582919.5000 - val_loss: 3395943.2500\n",
      "Epoch 660/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4064686.7500 - val_loss: 4241381.5000\n",
      "Epoch 661/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3555073.7500 - val_loss: 4296082.0000\n",
      "Epoch 662/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3406540.2500 - val_loss: 4242672.5000\n",
      "Epoch 663/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3474891.2500 - val_loss: 3401557.7500\n",
      "Epoch 664/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5541586.0000 - val_loss: 5660609.5000\n",
      "Epoch 665/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 5016903.5000 - val_loss: 6378187.5000\n",
      "Epoch 666/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4258024.0000 - val_loss: 5567389.5000\n",
      "Epoch 667/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3615495.7500 - val_loss: 4039750.2500\n",
      "Epoch 668/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3844536.7500 - val_loss: 3829271.7500\n",
      "Epoch 669/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3295856.7500 - val_loss: 3394855.2500\n",
      "Epoch 670/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 2824527.7500 - val_loss: 4190822.7500\n",
      "Epoch 671/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3152814.2500 - val_loss: 3397052.0000\n",
      "Epoch 672/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3406032.7500 - val_loss: 3424659.0000\n",
      "Epoch 673/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2826446.7500 - val_loss: 3662833.2500\n",
      "Epoch 674/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2958660.7500 - val_loss: 3770670.0000\n",
      "Epoch 675/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2863120.2500 - val_loss: 3498320.0000\n",
      "Epoch 676/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3216251.7500 - val_loss: 3531708.0000\n",
      "Epoch 677/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4048103.0000 - val_loss: 10370085.0000\n",
      "Epoch 678/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5124067.5000 - val_loss: 3396333.0000\n",
      "Epoch 679/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4452060.5000 - val_loss: 4338844.5000\n",
      "Epoch 680/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4226556.0000 - val_loss: 4623596.0000\n",
      "Epoch 681/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4144552.2500 - val_loss: 5851340.0000\n",
      "Epoch 682/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4509396.0000 - val_loss: 4403674.5000\n",
      "Epoch 683/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4293607.5000 - val_loss: 3431574.0000\n",
      "Epoch 684/5000\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 3474414.7500 - val_loss: 3997576.7500\n",
      "Epoch 685/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 3481257.2500 - val_loss: 3416277.2500\n",
      "Epoch 686/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 2803181.2500 - val_loss: 3825299.7500\n",
      "Epoch 687/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3543337.0000 - val_loss: 3820835.7500\n",
      "Epoch 688/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3418826.7500 - val_loss: 3911248.7500\n",
      "Epoch 689/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3155655.7500 - val_loss: 3430401.2500\n",
      "Epoch 690/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2974982.0000 - val_loss: 3629791.2500\n",
      "Epoch 691/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3828279.2500 - val_loss: 5236334.0000\n",
      "Epoch 692/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3320013.2500 - val_loss: 3428688.2500\n",
      "Epoch 693/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3318869.7500 - val_loss: 3396004.0000\n",
      "Epoch 694/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3431056.0000 - val_loss: 3566999.7500\n",
      "Epoch 695/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2810601.2500 - val_loss: 3460807.2500\n",
      "Epoch 696/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3089640.2500 - val_loss: 3655225.7500\n",
      "Epoch 697/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2936431.7500 - val_loss: 3474909.2500\n",
      "Epoch 698/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 3005896.7500 - val_loss: 3538953.2500\n",
      "Epoch 699/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3097363.2500 - val_loss: 3721699.7500\n",
      "Epoch 700/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4065680.0000 - val_loss: 4774466.0000\n",
      "Epoch 701/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4988360.5000 - val_loss: 5331369.5000\n",
      "Epoch 702/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3748684.0000 - val_loss: 3774811.2500\n",
      "Epoch 703/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3081443.0000 - val_loss: 3757582.7500\n",
      "Epoch 704/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3178509.0000 - val_loss: 3853913.2500\n",
      "Epoch 705/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3028329.7500 - val_loss: 3879108.2500\n",
      "Epoch 706/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2734894.0000 - val_loss: 3962903.2500\n",
      "Epoch 707/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3446412.0000 - val_loss: 4057286.2500\n",
      "Epoch 708/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3255048.2500 - val_loss: 5242887.5000\n",
      "Epoch 709/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4329678.5000 - val_loss: 3719158.0000\n",
      "Epoch 710/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5626904.5000 - val_loss: 11925005.0000\n",
      "Epoch 711/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 8758406.0000 - val_loss: 3398450.2500\n",
      "Epoch 712/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7431212.0000 - val_loss: 8737740.0000\n",
      "Epoch 713/5000\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 5179363.5000 - val_loss: 5003679.5000\n",
      "Epoch 714/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3578596.7500 - val_loss: 5924702.5000\n",
      "Epoch 715/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3325699.0000 - val_loss: 4300772.5000\n",
      "Epoch 716/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3866354.2500 - val_loss: 5053329.5000\n",
      "Epoch 717/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4131178.7500 - val_loss: 3712786.0000\n",
      "Epoch 718/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3314811.2500 - val_loss: 3398484.0000\n",
      "Epoch 719/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2978215.2500 - val_loss: 3435419.7500\n",
      "Epoch 720/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3174655.2500 - val_loss: 3410876.0000\n",
      "Epoch 721/5000\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 2911929.2500 - val_loss: 3791435.2500\n",
      "Epoch 722/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2941070.0000 - val_loss: 3396163.0000\n",
      "Epoch 723/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3074153.2500 - val_loss: 4561118.5000\n",
      "Epoch 724/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4172295.2500 - val_loss: 3520984.0000\n",
      "Epoch 725/5000\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 4753997.5000 - val_loss: 8614949.0000\n",
      "Epoch 726/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 4373246.0000 - val_loss: 3642882.7500\n",
      "Epoch 727/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3346291.0000 - val_loss: 3683809.2500\n",
      "Epoch 728/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3824094.2500 - val_loss: 5896370.5000\n",
      "Epoch 729/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4406027.5000 - val_loss: 3887724.0000\n",
      "Epoch 730/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3767437.2500 - val_loss: 3893711.2500\n",
      "Epoch 731/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2907976.2500 - val_loss: 3651349.0000\n",
      "Epoch 732/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2987546.0000 - val_loss: 3940192.2500\n",
      "Epoch 733/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3042207.2500 - val_loss: 3419484.7500\n",
      "Epoch 734/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3075887.2500 - val_loss: 3480901.2500\n",
      "Epoch 735/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3319902.7500 - val_loss: 3995718.7500\n",
      "Epoch 736/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3606741.0000 - val_loss: 3485009.0000\n",
      "Epoch 737/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3782588.0000 - val_loss: 5825760.5000\n",
      "Epoch 738/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3790311.2500 - val_loss: 3446576.2500\n",
      "Epoch 739/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2912067.7500 - val_loss: 4094173.0000\n",
      "Epoch 740/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2856158.0000 - val_loss: 3408329.0000\n",
      "Epoch 741/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3166255.7500 - val_loss: 6838952.0000\n",
      "Epoch 742/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4849784.0000 - val_loss: 4995152.5000\n",
      "Epoch 743/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 7304961.5000 - val_loss: 9758091.0000\n",
      "Epoch 744/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 6848005.5000 - val_loss: 3427345.0000\n",
      "Epoch 745/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 3198581.2500 - val_loss: 3414239.2500\n",
      "Epoch 746/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3009726.0000 - val_loss: 3698057.0000\n",
      "Epoch 747/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3996190.7500 - val_loss: 4804093.5000\n",
      "Epoch 748/5000\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 4443476.5000 - val_loss: 4200085.0000\n",
      "Epoch 749/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 5485746.0000 - val_loss: 3936190.7500\n",
      "Epoch 750/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 6548628.5000 - val_loss: 11417067.0000\n",
      "Epoch 751/5000\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 7383910.5000 - val_loss: 3962732.0000\n",
      "Epoch 752/5000\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 3952285.0000 - val_loss: 6393320.5000\n",
      "Epoch 753/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4073893.0000 - val_loss: 3642013.2500\n",
      "Epoch 754/5000\n",
      "6/6 [==============================] - 0s 7ms/step - loss: 3452197.0000 - val_loss: 3525426.2500\n",
      "Epoch 755/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2967562.7500 - val_loss: 3495255.2500\n",
      "Epoch 756/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3063121.2500 - val_loss: 3744635.7500\n",
      "Epoch 757/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3493927.0000 - val_loss: 4178699.7500\n",
      "Epoch 758/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 2856564.0000 - val_loss: 3565334.0000\n",
      "Epoch 759/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3222343.0000 - val_loss: 3857287.2500\n",
      "Epoch 760/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3379220.7500 - val_loss: 3533463.2500\n",
      "Epoch 761/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 3823044.0000 - val_loss: 3695018.0000\n",
      "Epoch 762/5000\n",
      "6/6 [==============================] - 0s 8ms/step - loss: 4995092.5000 - val_loss: 4738754.0000\n",
      "Epoch 763/5000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 4593952.5000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m      8\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m      9\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(hid_dim, activation\u001b[39m=\u001b[39mact_func, input_shape\u001b[39m=\u001b[39m(X_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m],)),\n\u001b[0;32m     10\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(hid_dim, activation\u001b[39m=\u001b[39mact_func),\n\u001b[0;32m     11\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m)])\n\u001b[0;32m     13\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmse\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49mnum_epochs, batch_size\u001b[39m=\u001b[39;49mbatch_size, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\engine\\training.py:1729\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1714\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1715\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[0;32m   1716\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[0;32m   1717\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1727\u001b[0m         steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution,\n\u001b[0;32m   1728\u001b[0m     )\n\u001b[1;32m-> 1729\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[0;32m   1730\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[0;32m   1731\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[0;32m   1732\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[0;32m   1733\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[0;32m   1734\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[0;32m   1735\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m   1736\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1737\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1738\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1739\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1740\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1741\u001b[0m )\n\u001b[0;32m   1742\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[0;32m   1743\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[0;32m   1744\u001b[0m }\n\u001b[0;32m   1745\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\engine\\training.py:2072\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   2068\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   2069\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m\"\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m   2070\u001b[0m ):\n\u001b[0;32m   2071\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 2072\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[0;32m   2073\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   2074\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:933\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    931\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    932\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[0;32m    934\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    935\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    936\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    141\u001b[0m   (concrete_function,\n\u001b[0;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1760\u001b[0m     args,\n\u001b[0;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1762\u001b[0m     executing_eagerly)\n\u001b[0;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "hid_dim = 64\n",
    "act_func = 'relu'\n",
    "num_epochs = 5000\n",
    "batch_size = 32\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(hid_dim, activation=act_func, input_shape=(X_train.shape[1],)),\n",
    "        tf.keras.layers.Dense(hid_dim, activation=act_func),\n",
    "        tf.keras.layers.Dense(1)])\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=num_epochs, batch_size=batch_size, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.models.save_model(model, 'ANN_monthly_peak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at ANN_monthly_peak",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mload_model(\u001b[39m'\u001b[39;49m\u001b[39mANN_monthly_peak\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\saving\\saving_api.py:212\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m saving_lib\u001b[39m.\u001b[39mload_model(\n\u001b[0;32m    205\u001b[0m         filepath,\n\u001b[0;32m    206\u001b[0m         custom_objects\u001b[39m=\u001b[39mcustom_objects,\n\u001b[0;32m    207\u001b[0m         \u001b[39mcompile\u001b[39m\u001b[39m=\u001b[39m\u001b[39mcompile\u001b[39m,\n\u001b[0;32m    208\u001b[0m         safe_mode\u001b[39m=\u001b[39msafe_mode,\n\u001b[0;32m    209\u001b[0m     )\n\u001b[0;32m    211\u001b[0m \u001b[39m# Legacy case.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m \u001b[39mreturn\u001b[39;00m legacy_sm_saving_lib\u001b[39m.\u001b[39;49mload_model(\n\u001b[0;32m    213\u001b[0m     filepath, custom_objects\u001b[39m=\u001b[39;49mcustom_objects, \u001b[39mcompile\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcompile\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[0;32m    214\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\MARC\\anaconda3\\envs\\myenv\\Lib\\site-packages\\keras\\saving\\legacy\\save.py:230\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(filepath_str, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    229\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo file or directory found at \u001b[39m\u001b[39m{\u001b[39;00mfilepath_str\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m         )\n\u001b[0;32m    234\u001b[0m     \u001b[39mif\u001b[39;00m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    235\u001b[0m         \u001b[39mreturn\u001b[39;00m saved_model_load\u001b[39m.\u001b[39mload(\n\u001b[0;32m    236\u001b[0m             filepath_str, \u001b[39mcompile\u001b[39m, options\n\u001b[0;32m    237\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at ANN_monthly_peak"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('ANN_monthly_peak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = model.evaluate(X_test, y_test)\n",
    "print('Test loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel('Actual Peak')\n",
    "plt.ylabel('Predicted Peak')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def mape(test, pred):\n",
    "    test, pred = np.array(test), np.array(pred)\n",
    "    mape = np.mean(np.abs((test - pred) / test))\n",
    "    return mape\n",
    "\n",
    "MSE  = mean_squared_error(y_test, y_pred)\n",
    "RMSE = math.sqrt(MSE)\n",
    "MAE  = mean_absolute_error(y_test, y_pred)\n",
    "MAPE = mape(y_test, y_pred)\n",
    "\n",
    "MSE, RMSE, MAE, MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sample = [67, 27, 109, 3000000]\n",
    "X_sample = scaler.transform([X_sample])\n",
    "\n",
    "y_hat = model.predict([X_sample])\n",
    "print(y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
