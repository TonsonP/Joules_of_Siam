{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.import the algorithms\n",
    "#Simple Regreesion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#Ensemble\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "\n",
    "lr  = LinearRegression(max_iter=1000,n_jobs = -1)\n",
    "rf  = RandomForestRegressor(n_jobs = -1)\n",
    "svr = SVR()\n",
    "gn = GaussianNB()\n",
    "ada = AdaBoostRegressor()\n",
    "br = BaggingRegressor()\n",
    "\n",
    "models = [lr, rf,  svr, gn, ada, br]\n",
    "scores = []\n",
    "\n",
    "#import the cross validation function \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits = 10, shuffle=True)\n",
    "\n",
    "#format: cross_val_score(model,xtrain,ytrain,cv=kfold(5),scoring='accuracy')\n",
    "for model in models:\n",
    "    scores.append(\n",
    "        cross_val_score(model, X_train, y_train, cv=kf, \n",
    "                         scoring='mean_squared_error')\n",
    "                  ) #try scoring='r2'\n",
    "\n",
    "print(scores)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. import the library\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth' : [5, 10],\n",
    "    'n_estimators' : [5, 6, 7, 8, 9, 10],\n",
    "    'max_features' : ['auto', 'log2'],\n",
    "}\n",
    "\n",
    "#3. define the model you want to search with\n",
    "estimator = #which model the best\n",
    "\n",
    "#4. define the gridsearch object with the search space\n",
    "grid = GridSearchCV(estimator  = estimator,\n",
    "                    param_grid = param_grid,\n",
    "                    cv = 5,  #by default, it uses kfold anyway; 5 here means 5 fold\n",
    "                    n_jobs  = -1,\n",
    "                    refit   = True, #refits means, after 24 loops, it will fit the best version again!, so grid = best model\n",
    "                    scoring = 'neg_mean_squared_error',\n",
    "                    return_train_score=True)\n",
    "\n",
    "#5. run the search\n",
    "grid.fit(X_train, y_train)  #why training set???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best parameters\n",
    "print(f\"Best params: {grid.best_params_}\")\n",
    "\n",
    "#best mse (score)\n",
    "print(f\"Best mse: {grid.best_score_}\")\n",
    "\n",
    "#you can retrieve the best model (basically the model trained the best_params_)\n",
    "print(f\"Best estimator: {grid.best_estimator_}\")  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Testing/Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = grid.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import math\n",
    "\n",
    "MSE  = mean_squared_error(y_test, yhat)\n",
    "RMSE = math.sqrt(MSE)\n",
    "MAE  = mean_absolute_error(y_test, yhat)\n",
    "\n",
    "MSE, RMSE, MAE"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
